{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNll8YVzg7RaOcfkSwwWZ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vagzikopis/SparkWordCount/blob/main/TweetAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e77UHBeDfqX6",
        "outputId": "938c4744-2289-419a-a694-4ae1f9d261dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: Top 5 Words per Sentiment\n",
            "+-----------------+---------+-----+\n",
            "|airline_sentiment|     word|count|\n",
            "+-----------------+---------+-----+\n",
            "|         negative|  jetblue|  990|\n",
            "|         negative|      get|  934|\n",
            "|         negative|cancelled|  864|\n",
            "|         negative|  service|  696|\n",
            "|         negative|    hours|  609|\n",
            "|          neutral|  jetblue|  685|\n",
            "|          neutral|      get|  227|\n",
            "|          neutral|   please|  172|\n",
            "|          neutral|     help|  150|\n",
            "|          neutral|   thanks|  147|\n",
            "|         positive|   thanks|  587|\n",
            "|         positive|  jetblue|  569|\n",
            "|         positive|    thank|  433|\n",
            "|         positive|    great|  222|\n",
            "|         positive|  service|  146|\n",
            "+-----------------+---------+-----+\n",
            "\n",
            "Question 2: Main Negative Reason per Airline\n",
            "+--------------+----------------------+-----+\n",
            "|airline       |negativereason        |count|\n",
            "+--------------+----------------------+-----+\n",
            "|American      |Customer Service Issue|654  |\n",
            "|Delta         |Late Flight           |228  |\n",
            "|Southwest     |Customer Service Issue|323  |\n",
            "|US Airways    |Customer Service Issue|698  |\n",
            "|United        |Customer Service Issue|545  |\n",
            "|Virgin America|Customer Service Issue|51   |\n",
            "+--------------+----------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower, regexp_replace, explode, split, desc, row_number, length\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "\n",
        "# Initialize the Spark Session and use DataFrame\n",
        "spark = SparkSession.builder.appName(\"AirlineAnalysis\").getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "df = spark.read.csv(\"tweets.csv\", header=True, inferSchema=True)\n",
        "# Extract all airline names\n",
        "airline_names = [row.airline.lower() for row in df.select(\"airline\").distinct().filter(col(\"airline\").isNotNull()).collect()]\n",
        "expanded_airlines = []\n",
        "for name in airline_names:\n",
        "    air_name = name.replace(\" \", \"\")\n",
        "    expanded_airlines.append(air_name)\n",
        "    expanded_airlines.append(air_name)\n",
        "    expanded_airlines.append(air_name + \"air\")\n",
        "    expanded_airlines.append(air_name + \"airline\")\n",
        "    expanded_airlines.append(air_name + \"airlines\")\n",
        "    expanded_airlines.append(air_name + \"airway\")\n",
        "    expanded_airlines.append(air_name + \"airways\")\n",
        "# 3. Data Preprocessing & Cleaning\n",
        "# Remove punctuation\n",
        "# Convert all to lowercase\n",
        "clean_df = df.withColumn(\"clean_text\", lower(regexp_replace(col(\"text\"), r'[^\\w\\s]', \"\")))\n",
        "\n",
        "# Question 1: Top 5 words per Sentiment\n",
        "# Filter out rows where 'clean_text' is null or empty before splitting,\n",
        "# as StopWordsRemover can't process null or empty arrays.\n",
        "clean_df = clean_df.filter(col(\"clean_text\").isNotNull() & (length(col(\"clean_text\")) > 0))\n",
        "\n",
        "# Split the cleaned text into an array of words\n",
        "tokens_df = clean_df.withColumn(\"words_array\", split(col(\"clean_text\"), \" \"))\n",
        "\n",
        "# Stop Word Removal\n",
        "# Use StopWordsRemover that filters out common stop words that don't carry sentiment meaning\n",
        "remover = StopWordsRemover(inputCol=\"words_array\", outputCol=\"filtered_words\")\n",
        "# Merge airline names with stop_words\n",
        "custom_stop_words = remover.getStopWords() + expanded_airlines + [\"flight\", \"flights\"]\n",
        "remover.setStopWords(custom_stop_words)\n",
        "\n",
        "# Apply the transformation\n",
        "df_filtered = remover.transform(tokens_df)\n",
        "\n",
        "# Explode and Filter\n",
        "# explode() turns the array of words into individual rows (one row per word)\n",
        "# Filter for length > 1 to remove single characters that do not carry sentiment meaning\n",
        "words_df = df_filtered.select(\"airline_sentiment\", explode(col(\"filtered_words\")).alias(\"word\")) \\\n",
        "    .filter(length(col(\"word\")) > 1)\n",
        "\n",
        "# Word Count\n",
        "# Group by sentiment type and the word itself to get the frequency\n",
        "word_counts = words_df.groupBy(\"airline_sentiment\", \"word\").count()\n",
        "\n",
        "# Window Function for Ranking\n",
        "# Partition by sentiment and order by count descending to find the top words for each group\n",
        "sentiment_window = Window.partitionBy(\"airline_sentiment\").orderBy(desc(\"count\"))\n",
        "\n",
        "top_5_words = word_counts.withColumn(\"rank\", row_number().over(sentiment_window)) \\\n",
        "    .filter(col(\"rank\") <= 5) \\\n",
        "    .select(\"airline_sentiment\", \"word\", \"count\")\n",
        "\n",
        "print(\"Question 1: Top 5 Words per Sentiment\")\n",
        "top_5_words.show()\n",
        "\n",
        "# Question 2: Main Negative Reason per Airline\n",
        "# Ignore rows with confidence <= 0.5 and skip null values\n",
        "negative_df = df.filter((col(\"negativereason_confidence\") > 0.5) & (col(\"negativereason\").isNotNull()))\n",
        "\n",
        "# Group by Airline and Reason and perform word count\n",
        "reason_counts = negative_df.groupBy(\"airline\", \"negativereason\").count()\n",
        "\n",
        "# Window Function for Top Reason\n",
        "# Partition by airline and pick the the highest count\n",
        "airline_window = Window.partitionBy(\"airline\").orderBy(desc(\"count\"))\n",
        "\n",
        "top_reasons = reason_counts.withColumn(\"rank\", row_number().over(airline_window)) \\\n",
        "    .filter(col(\"rank\") == 1) \\\n",
        "    .select(\"airline\", \"negativereason\", \"count\")\n",
        "\n",
        "print(\"Question 2: Main Negative Reason per Airline\")\n",
        "top_reasons.show(truncate=False)"
      ]
    }
  ]
}